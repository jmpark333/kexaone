"""
K-EXAONE ì±„íŒ… UI ì˜ˆì œ
Streamlitì„ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤

ì„¤ì¹˜ ë°©ë²•:
pip install streamlit openai

ì‹¤í–‰ ë°©ë²•:
streamlit run app.py
"""

import streamlit as st
from openai import OpenAI
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="K-EXAONE Chat", page_icon="ğŸ¤–", layout="wide")

# API ì„¤ì •
BASE_URL = "https://api.friendli.ai/serverless/v1"
MODEL = "LGAI-EXAONE/K-EXAONE-236B-A23B"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "thinking_mode" not in st.session_state:
    st.session_state.thinking_mode = True

if "auto_send" not in st.session_state:
    st.session_state.auto_send = False

if "api_key" not in st.session_state:
    st.session_state.api_key = ""


# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def get_client(api_key):
    return OpenAI(
        api_key=api_key,
        base_url=BASE_URL,
    )


# í”„ë¡¬í”„íŠ¸ ì˜ˆì œ
PROMPT_EXAMPLES = {
    "ğŸ§  ì¶”ë¡  ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸": """ë‹¤ìŒ ë…¼ë¦¬ í¼ì¦ì„ ë‹¨ê³„ë³„ë¡œ í•´ê²°í•´ì£¼ì„¸ìš”:

ë¬¸ì œ: 5ëª…ì˜ ì‚¬ëŒ(A, B, C, D, E)ê°€ ì¼ë ¬ë¡œ ì„œ ìˆìŠµë‹ˆë‹¤.
- AëŠ” Cì˜ ë°”ë¡œ ì˜†ì— ì„œ ìˆìŠµë‹ˆë‹¤.
- BëŠ” Dì˜ ì™¼ìª½ì— ì„œ ìˆìŠµë‹ˆë‹¤.
- EëŠ” ì–‘ ë ì¤‘ í•œ ê³³ì— ì„œ ìˆìŠµë‹ˆë‹¤.
- CëŠ” Eì˜ ì˜¤ë¥¸ìª½ì— ì„œ ìˆìŠµë‹ˆë‹¤.

ì •í™•í•œ ì„œ ìˆëŠ” ìˆœì„œë¥¼ ëŒ€ë¡œë¡œ ì„¤ëª…í•˜ê³ , ê° ë‹¨ê³„ì˜ ì¶”ë¡  ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”.""",
    "ğŸ“Š ìˆ˜í•™ ë¬¸ì œ í•´ê²°": """ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í•´ê²°í•´ì£¼ì„¸ìš”:

ë¬¸ì œ: í•œ íšŒì‚¬ì—ì„œ ì§ì›ë“¤ì—ê²Œ ë³´ë„ˆìŠ¤ë¥¼ ë¶„ë°°í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
- ì²« ë²ˆì§¸ ì§ì›ì€ ì „ì²´ ë³´ë„ˆìŠ¤ì˜ 1/3ì„ ë°›ìŠµë‹ˆë‹¤.
- ë‘ ë²ˆì§¸ ì§ì›ì€ ë‚¨ì€ ê¸ˆì•¡ì˜ 1/4ì„ ë°›ìŠµë‹ˆë‹¤.
- ì„¸ ë²ˆì§¸ ì§ì›ì€ ê·¸ ë‹¤ìŒ ë‚¨ì€ ê¸ˆì•¡ì˜ 1/5ë¥¼ ë°›ìŠµë‹ˆë‹¤.
- ë§ˆì§€ë§‰ìœ¼ë¡œ ë‚¨ì€ ê¸ˆì•¡ì€ $120,000ì…ë‹ˆë‹¤.

ì´ˆê¸° ì „ì²´ ë³´ë„ˆìŠ¤ ê¸ˆì•¡ê³¼ ê° ì§ì›ì´ ë°›ì€ ê¸ˆì•¡ì„ ê³„ì‚°í•´ì£¼ì„¸ìš”.""",
    "ğŸ“š ì¥ë¬¸ì„œ ìš”ì•½ í…ŒìŠ¤íŠ¸": """ë‹¤ìŒ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  í•µì‹¬ ë‚´ìš©ì„ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

[í…ìŠ¤íŠ¸ ì‹œì‘]
ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ë„ë¡ ë§Œë“œëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ê¸°ê³„í•™ìŠµ, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ í•˜ìœ„ ë¶„ì•¼ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ìµœê·¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ìœ¼ë¡œ AIëŠ” í…ìŠ¤íŠ¸ ìƒì„±, ë²ˆì—­, ìš”ì•½, ì§ˆë¬¸ ë‹µë³€ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ì¸ê°„ ìˆ˜ì¤€ ì´ìƒì˜ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ OpenAIì˜ GPT ì‹œë¦¬ì¦ˆ, êµ¬ê¸€ì˜ Gemini, ì•Œë¦¬ë°”ë°”ì˜ Qwen, ê·¸ë¦¬ê³  LGì˜ K-EXAONE ë“± ê²½ìŸ ëª¨ë¸ë“¤ì´ ì†ì† ë“±ì¥í•˜ë©° AI ê¸°ìˆ  ê²½ìŸì´ ì¹˜ì—´í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. í•œí¸ìœ¼ë¡œëŠ” AIê°€ ì¼ìë¦¬ë¥¼ ëŒ€ì²´í•  ê²ƒì´ë¼ëŠ” ìš°ë ¤ì™€ í•¨ê»˜, ë‹¤ë¥¸ í•œí¸ìœ¼ë¡œëŠ” ìƒˆë¡œìš´ ê¸°íšŒë¥¼ ì°½ì¶œí•  ê²ƒì´ë¼ëŠ” ê¸°ëŒ€ê°€ ê³µì¡´í•©ë‹ˆë‹¤. ì „ë¬¸ê°€ë“¤ì€ AI í™œìš© ëŠ¥ë ¥ì´ ë¯¸ë˜ ì§ì—… ì‹œì¥ì—ì„œ í•µì‹¬ ì—­ëŸ‰ì´ ë  ê²ƒì´ë¼ê³  ì „ë§í•©ë‹ˆë‹¤.
[í…ìŠ¤íŠ¸ ë]

ì´ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ: 1) AI ê¸°ìˆ ì˜ í˜„ ìƒí™©, 2) ì£¼ìš” ëª¨ë¸ë“¤, 3) ì‚¬íšŒì  ì˜í–¥ì„ í¬í•¨í•˜ì—¬ ìš”ì•½í•´ì£¼ì„¸ìš”.""",
    "ğŸ‡°ğŸ‡· í•œêµ­ì–´ ë¬¸í™” ë§¥ë½ ì´í•´": """ë‹¤ìŒ ì§ˆë¬¸ì— í•œêµ­ì˜ ë¬¸í™”ì , ì—­ì‚¬ì  ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: í•œêµ­ì˜ 'ì •ì›”ëŒ€ë³´ë¦„'ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ ì£¼ì„¸ìš”:
1. ìŒë ¥ìœ¼ë¡œ ì–¸ì œì¸ì§€
2. ì „í†µì ìœ¼ë¡œ ë¨¹ëŠ” ìŒì‹ê³¼ ê·¸ ì˜ë¯¸
3. í•˜ëŠ” ë†€ì´ì™€ í’ìŠµ
4. í˜„ëŒ€ í•œêµ­ ì‚¬íšŒì—ì„œì˜ ì˜ë¯¸

ê°€ëŠ¥í•œí•œ í•œêµ­ì¸ì˜ ê´€ì ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.""",
    "ğŸ’» ì½”ë”© ë¬¸ì œ í•´ê²°": """ë‹¤ìŒ íŒŒì´ì¬ ì½”ë”© ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ì„¸ìš”:

ë¬¸ì œ:
1. ì£¼ì–´ì§„ ì •ìˆ˜ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì—°ì†ëœ ë¶€ë¶„ ë¦¬ìŠ¤íŠ¸ì˜ í•©ì´ ìµœëŒ€ê°€ ë˜ëŠ” ë¶€ë¶„ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
2. ì˜ˆë¥¼ ë“¤ì–´, [-2, 1, -3, 4, -1, 2, 1, -5, 4]ì—ì„œ ìµœëŒ€ í•©ì„ ê°–ëŠ” ë¶€ë¶„ ë¦¬ìŠ¤íŠ¸ëŠ” [4, -1, 2, 1]ì´ê³  í•©ì€ 6ì…ë‹ˆë‹¤.
3. ì‹œê°„ ë³µì¡ë„ëŠ” O(n)ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
4. í•¨ìˆ˜ë¿ë§Œ ì•„ë‹ˆë¼ í…ŒìŠ¤íŠ¸ ì½”ë“œì™€ ì„¤ëª…ë„ í¬í•¨í•´ì£¼ì„¸ìš”.
5. ì½”ë“œì— ëŒ€í•œ ì„¤ëª…ì„ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.""",
}

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ¤– K-EXAONE Chat")
    st.markdown("---")

    # API í‚¤ ì…ë ¥
    st.subheader("ğŸ”‘ API í‚¤ ì„¤ì •")
    api_key_input = st.text_input(
        "FRIENDLI_TOKEN (API Key)",
        type="password",
        placeholder="FriendliAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
        value=st.session_state.api_key,
        help="FriendliAIì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
    )
    st.session_state.api_key = api_key_input

    st.markdown("---")

    # ëª¨ë¸ ì„¤ì •
    st.subheader("âš™ï¸ ì„¤ì •")
    thinking_mode = st.checkbox(
        "ì¶”ë¡  ëª¨ë“œ (Thinking Mode)", value=True, help="ëª¨ë¸ì˜ ì‚¬ê³  ê³¼ì •ì„ í‘œì‹œí•©ë‹ˆë‹¤"
    )
    st.session_state.thinking_mode = thinking_mode

    st.markdown("---")

    # í”„ë¡¬í”„íŠ¸ ì˜ˆì œ
    st.subheader("ğŸ“ í”„ë¡¬í”„íŠ¸ ì˜ˆì œ")
    st.markdown("ì•„ë˜ ì˜ˆì œë¥¼ í´ë¦­í•˜ë©´ ì…ë ¥ì°½ì— ìë™ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤:")

    for title, prompt in PROMPT_EXAMPLES.items():
        if st.button(
            title, key=f"btn_{title}_{hash(prompt)}", use_container_width=True
        ):
            st.session_state.messages = []
            st.session_state.user_input = prompt
            st.session_state.auto_send = True
            st.rerun()

    st.markdown("---")

    # ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.session_state.user_input = ""
        st.rerun()

    st.markdown("---")
    st.markdown("""
    ### ğŸ’¡ ì‚¬ìš© íŒ
    - K-EXAONEì€ **256K ì»¨í…ìŠ¤íŠ¸**ë¥¼ ì§€ì›í•©ë‹ˆë‹¤
    - **í•œêµ­ì–´** ì²˜ë¦¬ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤
    - **ì¶”ë¡  ëª¨ë“œ**ì—ì„œ ì‚¬ê³  ê³¼ì •ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - **ìˆ˜í•™**, **ì½”ë”©**, **ì¥ë¬¸ì„œ ì´í•´**ì— ê°•ì ì´ ìˆìŠµë‹ˆë‹¤
    """)

# ë©”ì¸ ì˜ì—­
st.title("ğŸ¤– K-EXAONE ëŒ€í™”í•˜ê¸°")
st.markdown(f"**ëª¨ë¸**: {MODEL} | **ì¶”ë¡  ëª¨ë“œ**: {'âœ…' if thinking_mode else 'âŒ'}")

# API í‚¤ í™•ì¸
if not st.session_state.api_key:
    st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ FriendliAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# ì±„íŒ… history í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["role"] == "user":
            st.markdown(message["content"])
        else:
            # ì¶”ë¡  ë‚´ìš©ì´ ìˆë‹¤ë©´ ë¨¼ì € í‘œì‹œ
            if "reasoning" in message and thinking_mode:
                with st.expander("ğŸ§  ì‚¬ê³  ê³¼ì • (Reasoning)", expanded=False):
                    st.markdown(message["reasoning"])
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì˜ì—­
st.markdown("---")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì…ë ¥ê°’ ê´€ë¦¬ìš©)
if "user_input" not in st.session_state:
    st.session_state.user_input = ""

# ì…ë ¥ì°½ê³¼ ì „ì†¡ ë²„íŠ¼ì„ colìœ¼ë¡œ ë‚˜ëˆ„ê¸°
col1, col2 = st.columns([4, 1])

with col1:
    # ì…ë ¥ì°½ ì´ˆê¸°ê°’ ì„¤ì • (ì„¸ì…˜ ìƒíƒœì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°)
    input_value = st.session_state.get("user_input", "")

    user_input = st.text_area(
        "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", height=35, value=input_value, key="user_input"
    )

with col2:
    st.markdown(f'<div style="margin-top: 55px;"></div>', unsafe_allow_html=True)
    send_button = st.button("ì „ì†¡", use_container_width=True, type="primary")

# í˜ì´ì§€ ë¡œë“œ ì‹œ ìë™ ì „ì†¡ í™•ì¸
if (
    st.session_state.auto_send
    and st.session_state.user_input
    and st.session_state.user_input.strip()
):
    # ìë™ ì „ì†¡ í”Œë˜ê·¸ ì´ˆê¸°í™”
    st.session_state.auto_send = False

    # ì…ë ¥ê°’ ì €ì¥ (ì…ë ¥ì°½ ì´ˆê¸°í™” ì „ì—)
    current_input = st.session_state.user_input

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": current_input})

    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(current_input)

    # ì…ë ¥ì°½ ì´ˆê¸°í™”
    st.session_state.user_input = ""

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
    with st.chat_message("assistant"):
        try:
            client = get_client(st.session_state.api_key)
            extra_body = {
                "parse_reasoning": True,
                "chat_template_kwargs": {"enable_thinking": thinking_mode},
            }

            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            stream = client.chat.completions.create(
                model=MODEL,
                extra_body=extra_body,
                messages=st.session_state.messages,
                stream=True,
            )

            # ì¶”ë¡  ë‚´ìš©ê³¼ ìµœì¢… ì‘ë‹µì„ ì €ì¥í•  ë³€ìˆ˜
            full_reasoning = ""
            full_content = ""

            # placeholder ìƒì„±
            reasoning_placeholder = st.empty() if thinking_mode else None
            content_placeholder = st.empty()

            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            for chunk in stream:
                delta = chunk.choices[0].delta

                reasoning_content = getattr(delta, "reasoning_content", None)
                content = getattr(delta, "content", None)

                if reasoning_content:
                    full_reasoning += reasoning_content
                    if thinking_mode and reasoning_placeholder:
                        reasoning_placeholder.markdown(full_reasoning)

                if content:
                    full_content += content
                    content_placeholder.markdown(full_content)

            # ë©”ì‹œì§€ ì €ì¥
            message_data = {"role": "assistant", "content": full_content}
            if full_reasoning:
                message_data["reasoning"] = full_reasoning
            st.session_state.messages.append(message_data)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.markdown("ğŸ’¡ **í•´ê²° ë°©ë²•**:")
            st.markdown("- API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”")
            st.markdown("- ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
            st.markdown("- FriendliAI ì„œë¹„ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”")

    st.rerun()

# ì „ì†¡ ë²„íŠ¼ í´ë¦­ ë˜ëŠ” Enter í‚¤ ì²˜ë¦¬
if send_button and user_input and user_input.strip():
    # ì…ë ¥ê°’ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.user_input = user_input

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})

    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_input)

    # ì…ë ¥ì°½ ì´ˆê¸°í™”
    st.session_state.user_input = ""

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
    with st.chat_message("assistant"):
        try:
            client = get_client(st.session_state.api_key)
            extra_body = {
                "parse_reasoning": True,
                "chat_template_kwargs": {"enable_thinking": thinking_mode},
            }

            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            stream = client.chat.completions.create(
                model=MODEL,
                extra_body=extra_body,
                messages=st.session_state.messages,
                stream=True,
            )

            # ì¶”ë¡  ë‚´ìš©ê³¼ ìµœì¢… ì‘ë‹µì„ ì €ì¥í•  ë³€ìˆ˜
            full_reasoning = ""
            full_content = ""

            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            for chunk in stream:
                delta = chunk.choices[0].delta

                reasoning_content = getattr(delta, "reasoning_content", None)
                content = getattr(delta, "content", None)

                if reasoning_content:
                    full_reasoning += reasoning_content
                    if st.session_state.thinking_mode:
                        st.write(reasoning_content)

                if content:
                    full_content += content
                    st.write(content)

            # ë©”ì‹œì§€ ì €ì¥
            message_data = {"role": "assistant", "content": full_content}
            if full_reasoning:
                message_data["reasoning"] = full_reasoning
            st.session_state.messages.append(message_data)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.markdown("ğŸ’¡ **í•´ê²° ë°©ë²•**:")
            st.markdown("- API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”")
            st.markdown("- ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
            st.markdown("- FriendliAI ì„œë¹„ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”")

    st.rerun()

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("""
### ğŸ“Š K-EXAONE í•µì‹¬ ì„±ëŠ¥
- **ì´ íŒŒë¼ë¯¸í„°**: 236B (í™œì„±: 23B)
- **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´**: 256K í† í°
- **ì§€ì› ì–¸ì–´**: í•œêµ­ì–´, ì˜ì–´, ìŠ¤í˜ì¸ì–´, ë…ì¼ì–´, ì¼ë³¸ì–´, ë² íŠ¸ë‚¨ì–´
- **íŠ¹í™” ë¶„ì•¼**: ì¶”ë¡ , ìˆ˜í•™, ì½”ë”©, ì¥ë¬¸ì„œ ì²˜ë¦¬

### ğŸ”— ê´€ë ¨ ë§í¬
- [Hugging Face](https://huggingface.co/LGAI-EXAONE/K-EXAONE-236B-A23B)
- [GitHub](https://github.com/LG-AI-EXAONE/K-EXAONE)
- [ê¸°ìˆ  ë³´ê³ ì„œ](https://arxiv.org/pdf/2601.01739)
""")

# CSS ìŠ¤íƒ€ì¼
st.markdown(
    """
<style>
    .stChatMessage {
        background-color: #f0f7ff;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
    }
    .stTextArea {
        background-color: #ffffff;
    }
    .stButton>button {
        border-radius: 5px;
    }
</style>
""",
    unsafe_allow_html=True,
)
